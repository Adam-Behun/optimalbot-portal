# Call type determines how calls are initiated
# dial-out: Bot calls the user (outbound)
# dial-in: User calls the bot (inbound)
call_type: "dial-in"

services:
  stt:
    api_key: ${DEEPGRAM_API_KEY}
    model: flux-general-en
    eager_eot_threshold: 0.45
    eot_threshold: 0.55
    eot_timeout_ms: 2500

  # Main LLM for complex tasks: spelling, verification, function calling
  # Used for confirmation, date/time selection, and any node requiring accuracy
#  llm:
#    provider: anthropic
#    model: claude-haiku-4-5-20251001
#    temperature: 0.3
#    api_key: ${ANTHROPIC_API_KEY}
#    max_tokens: 256

  llm:
    provider: openai  # Main LLM for conversation and IVR navigation
    model: gpt-4o-mini  # Capable model for complex tasks
    temperature: 0.4  # Sampling temperature (0-2); higher values make output more creative/random, lower more deterministic/focused.
    api_key: ${OPENAI_API_KEY}  # API authentication key.
    max_tokens: 256  # Maximum tokens in response; limits output length to prevent long delays in generation.
    service_tier: priority  # Priority processing for lower latency


  # Classifier LLM for simple conversational tasks
  # Fast model for greetings, simple info collection (name, phone, email)
  # NO function calling - purely conversational
  classifier_llm:
    provider: groq
    model: llama-3.3-70b-versatile # llama-3.1-8b-instant  # Ultra-fast for simple interactions
    temperature: 0.5  # Slightly creative for natural conversation
    api_key: ${GROQ_API_KEY}
    max_tokens: 150  # Keep responses short and snappy

  tts:
    provider: cartesia
    model: sonic-3-2025-10-27
    voice_id: 829ccd10-f8b3-43cd-b8a0-4aeaa81f3b30
    api_key: ${CARTESIA_API_KEY}
    generation_config:
      speed: 1
      volume: 1.0
      emotion: neutral
    aggregate_sentences: true

  transport:
    provider: daily
    api_key: ${DAILY_API_KEY}
    phone_number_id: ${DAILY_PHONE_NUMBER_ID}
    enable_echo_cancellation: true
    audio_in_sample_rate: 16000
    audio_out_sample_rate: 24000

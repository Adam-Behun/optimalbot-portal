services:
  stt:
    provider: deepgram  # The STT service provider (e.g., deepgram, assemblyai).
    model: nova-2-phonecall  # Model variant; nova-2-phonecall is optimized for telephony/low-latency calls.
    endpointing: 100  # Milliseconds of silence to detect utterance end; lower values speed up final transcripts but risk cutting off speech.
    api_key: ${DEEPGRAM_API_KEY}  # API authentication key.
    language: en-US  # Language code (e.g., en-US); specifies speech recognition language for better accuracy.
    detect_language: false  # Whether to auto-detect language; disable for consistent language in specific use cases.
    interim_results: false  # Whether to send partial transcripts; disable for lower latency on final results in simple flows.
    smart_format: true  # Automatically formats numbers/dates/times in transcripts; improves readability without much latency hit.
    vad_events: true  # Enables VAD event callbacks; integrates with external VAD for precise speech detection.

  llm:
    provider: openai  # The LLM provider (e.g., openai, grok).
    model: gpt-4o-mini  # Model name; gpt-4o-mini is faster/cheaper for low-latency responses.
    temperature: 0.4  # Sampling temperature (0-2); higher values make output more creative/random, lower more deterministic/focused.
    api_key: ${OPENAI_API_KEY}  # API authentication key.
    max_tokens: 100  # Maximum tokens in response; limits output length to prevent long delays in generation.
    top_p: 0.85  # Nucleus sampling (0-1); considers top probability mass for diversity; lower focuses on likely tokens for consistency.
    frequency_penalty: 0.5  # Penalty for repeating tokens ( -2 to 2); positive values reduce repetition for more natural dialogue.
    presence_penalty: 0.3  # Encourages staying on topic
    seed: 42  # Deterministic outputs for consistency

  # Classifier LLM for voicemail detection (cheaper model for binary classification)
  classifier_llm:
    provider: openai  # Same provider as main LLM
    model: gpt-4o-mini  # Cheaper model (~10x cost savings) for simple voicemail/conversation classification
    temperature: 0.1  # Lower temperature for more deterministic binary classification
    api_key: ${OPENAI_API_KEY}  # API authentication key
    max_tokens: 5  # Very low - only needs to output "CONVERSATION" or "VOICEMAIL"

  tts:
    provider: elevenlabs  # The TTS provider (e.g., elevenlabs, playht).
    model: eleven_flash_v2_5  # Model variant; turbo_v2 prioritizes low-latency synthesis for real-time voice.
    voice_id: 3dzJXoCYueSQiptQ6euE  # ID of the voice to use; selects timbre/style (e.g., custom cloned voices for branding).
    stability: 0.7  # Voice stability (0-1); lower values allow more variability/emotion but may increase latency slightly.
    api_key: ${ELEVENLABS_API_KEY}  # API authentication key.
    similarity_boost: 0.8  # Boosts voice likeness (0-1); higher improves accuracy to original voice but can slow synthesis.
    optimize_streaming_latency: 3  # Latency optimization level (0-4); higher values reduce delay at minor quality cost for streaming.
    output_format: pcm_24000  # Audio format (e.g., mp3_44100, pcm_16000); pcm_16000 is low-latency for telephony.
    style: 0.0  # Voice style (0-1); adjusts expressiveness/tone for more natural speech.

  transport:
    provider: daily  # The transport/telephony provider (e.g., daily, twilio).
    api_key: ${DAILY_API_KEY}  # API authentication key for room creation/access.
    phone_number_id: ${DAILY_PHONE_NUMBER_ID}  # ID for outbound dialing number; required for telephony.
    enable_echo_cancellation: true  # Enables server-side echo cancellation; reduces feedback/loops in calls for clearer audio.
    audio_in_sample_rate: 16000  # Input audio sample rate (Hz); 16000 is standard for telephony to minimize processing latency.
    audio_out_sample_rate: 24000  # Output audio sample rate (Hz); matches input for efficient streaming without resampling delays.